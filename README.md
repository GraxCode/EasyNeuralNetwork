# About
This is a really simple implementation of a neural network with x inputs, 2 hidden layers and one output written in java. It uses sigmoid or ReLU as activation function.  
If you are new to NNs this can help you understand forward- and backpropagation.